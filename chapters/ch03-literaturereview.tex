\chapter{Related Works}
\label{ch03:litreview}
Unfortunately, there is no recent research regarding the replication of Adabas to relational (or other) databases. While there is research regarding the replication of modern NoSQL databases such as MongoDB to relational databases \cite{aftabnosqletltordbms}, the modern NoSQL differs too much from Adabas for it to truly be comparable. Instead, the related works to specific technologies relevant to this thesis are be discussed.

\section{Adabas}
\label{ch03:litreview:adabas}
The state of research on Adabas is scarce and, for the most part, outdated. One such example is the research on creating a multi-database system with heterogeneous DBMSs (database management systems) based on \ac{CORBA} \cite{ozhan1996making}. This system included Adabas and Oracle7, a relational DBMS. Almost 30 years since that publication, \ac{CORBA} is considered obsolete \cite{fallofcorba}.

Another interesting, albeit outdated, paper documents the integration of Adabas with modern systems using the \ac{SOA} approach \cite{koschelmainframemodernization}. This paper explores the creation of a web service for interacting with Adabas using Natural programs. The web service used the \ac{SOAP} to communicate with the EntireX Broker, which then execute the Natural programs using \ac{RPC}. However, just as \ac{CORBA}, \ac{SOAP} is now considered an outdated technology \cite{soapoutdated}.

\section{Apache Kafka}
Several studies have explored the capabilities of Apache Kafka in different use cases. For instance, a research paper released by the co-creators of Kafka outlines how Kafka's design makes it more efficient and performant in comparison to other existing messaging systems such as Apache ActiveMQ \cite{kreps2011kafka}. The paper also discusses Kafka's performance guarantees and limitations when the Kafka cluster encounters extremely high throughput. It provides a description of how Kafka use used at LinkedIn, and an experimental study where the performance of Kafka is compared with Apache ActiveMQ and RabbitMQ. Another paper provides an overview of a possible architecture for implementing Kafka in a financial enterprise system for real-time data processing, reporting and alerting \cite{peddireddystreamliningprocessingkafka}. This paper also mentions using Kafka Connect (see also \ref{ch03:litreview:kafkaconnect}) for ingesting from different sources, providing case studies where Kafka has been implemented for real-time data processing. A further paper proposes a streaming system based on Kafka to replace a current event notification system based on ActiveMQ in a financial enterprise system \cite{sanjanaenterprise}. It also discusses using Kafka Streams, a built-in API for stream processing, for real-time transformations, aggregations, and analytics.

Overall, there is a wealth case studies and papers on Apache Kafka in general, with new papers still being published on a regular basis. They can be used to provide an overview of the features and benefits of Kafka and its use cases, as well as its existing limitations. The studies can also be used to explore the parallel processing abilities of Kafka, and how that might impact both performance and the consistency of the replication data. In the next section, the focus will be on Kafka Connect and its uses and performance concerning data integration.

\section{Kafka Connect}
\label{ch03:litreview:kafkaconnect}
For Kafka Connect specifically, the selection of scientific papers is considerably smaller. The majority of papers found do not focus on Kafka Connect as much, instead just covering it as a preferred way to ingest data into the Kafka-based pipeline, especially for big data event streaming \cite{padmanabankafkabigdataeventstreaming}.

Srijith et al. explores using Kafka Connect to improve on a performance bottleneck caused by using a fixed number of publisher threads when writing transaction logs from an SQL server and MongoDB server to Kafka \cite{srijithkafkaconnectperformance}. An experiment was performed with favorable results for Kafka Connect, allowing the bottleneck to be decreased and CPU and memory of running containers to be reduced. Another paper provides experimental evaluation of using Kafka Connect to improve the consistency and throughput for replicating data between databases \cite{adilaoptimizationkafkaconnect}. However, both the database source and integration database target are relational databases. Alternatively, one paper found explores the synchronization between MongoDB and MySQL using Kafka Connect and Debezium (a similar platform for capturing real-time database changes and streaming them into Kafka), with performance tests being done in both directions showcasing positive results \cite{sqlmongosync}.

% \section{Database Replication}